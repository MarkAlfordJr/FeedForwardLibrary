{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c3b8b5d",
   "metadata": {},
   "source": [
    "# Add Integers\n",
    "\n",
    "the objective of this FFN model is too add two integers together and predict the right result. the integers are between, and including,  -10 and 10,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f075549",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. data generation\n",
    "2. determine independent and dependent features\n",
    "3. split train and test data\n",
    "4. convert to tensors\n",
    "5. design model\n",
    "6. train model\n",
    "7. evaluate and experiment on model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e30977f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 397, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 752, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/d2/zb1dmj6x7tx9zth8l6bmjrs40000gn/T/ipykernel_7040/3570699554.py\", line 3, in <module>\n",
      "    import torch\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/markalford/Desktop/FeedForwardLibrary/FeedFowardLibray/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222401d",
   "metadata": {},
   "source": [
    "## 1. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2943c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21, 2),\n",
       " array([[-10.,  -9.],\n",
       "        [ -8.,  -7.],\n",
       "        [ -6.,  -5.],\n",
       "        [ -4.,  -3.],\n",
       "        [ -2.,  -1.],\n",
       "        [  0.,   1.],\n",
       "        [  2.,   3.],\n",
       "        [  4.,   5.],\n",
       "        [  6.,   7.],\n",
       "        [  8.,   9.],\n",
       "        [ 10.,   3.],\n",
       "        [  4.,   5.],\n",
       "        [  7.,  -5.],\n",
       "        [  5.,  -1.],\n",
       "        [ -5.,  -8.],\n",
       "        [ -4.,  -3.],\n",
       "        [  9.,   7.],\n",
       "        [  5.,   4.],\n",
       "        [  2.,   1.],\n",
       "        [ -9.,  -8.],\n",
       "        [ -7., -10.]], dtype=float32))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[-10,-9,-8,-7,-6,-5,-4,-3,-2,-1,0,1,2,3,4,5,6,7,8,9,10],\n",
    "                  [3,4,5,7,-5,5,-1,-5,-8,-4,-3,9,7,5,4,2,1,-9,-8,-7,-10]], dtype=np.float32)\n",
    "X = X.reshape(21,2)\n",
    "X.shape, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c551cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19.0\n",
      "-15.0\n",
      "-11.0\n",
      "-7.0\n",
      "-3.0\n",
      "1.0\n",
      "5.0\n",
      "9.0\n",
      "13.0\n",
      "17.0\n",
      "13.0\n",
      "9.0\n",
      "2.0\n",
      "4.0\n",
      "-13.0\n",
      "-7.0\n",
      "16.0\n",
      "9.0\n",
      "3.0\n",
      "-17.0\n",
      "-17.0\n",
      "this is the updated temp list[-19.0, -15.0, -11.0, -7.0, -3.0, 1.0, 5.0, 9.0, 13.0, 17.0, 13.0, 9.0, 2.0, 4.0, -13.0, -7.0, 16.0, 9.0, 3.0, -17.0, -17.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((21, 2), (21, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = []\n",
    "for sub_array in X:\n",
    "    print(sum(sub_array))\n",
    "    y.append(sum(sub_array).item())\n",
    "\n",
    "print(f'this is the updated temp list{y}')\n",
    "\n",
    "y = np.array(y, dtype=np.float32)\n",
    "y = y.reshape(21,1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea38c985",
   "metadata": {},
   "source": [
    "## 3. Split train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e08438ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float32'),\n",
       " dtype('float32'),\n",
       " array([[-10.,  -9.],\n",
       "        [ -8.,  -7.],\n",
       "        [ -6.,  -5.],\n",
       "        [ -4.,  -3.],\n",
       "        [ -2.,  -1.],\n",
       "        [  0.,   1.],\n",
       "        [  2.,   3.],\n",
       "        [  4.,   5.],\n",
       "        [  6.,   7.],\n",
       "        [  8.,   9.],\n",
       "        [ 10.,   3.],\n",
       "        [  4.,   5.],\n",
       "        [  7.,  -5.],\n",
       "        [  5.,  -1.],\n",
       "        [ -5.,  -8.],\n",
       "        [ -4.,  -3.],\n",
       "        [  9.,   7.],\n",
       "        [  5.,   4.],\n",
       "        [  2.,   1.],\n",
       "        [ -9.,  -8.],\n",
       "        [ -7., -10.]], dtype=float32),\n",
       " array([[-19.],\n",
       "        [-15.],\n",
       "        [-11.],\n",
       "        [ -7.],\n",
       "        [ -3.],\n",
       "        [  1.],\n",
       "        [  5.],\n",
       "        [  9.],\n",
       "        [ 13.],\n",
       "        [ 17.],\n",
       "        [ 13.],\n",
       "        [  9.],\n",
       "        [  2.],\n",
       "        [  4.],\n",
       "        [-13.],\n",
       "        [ -7.],\n",
       "        [ 16.],\n",
       "        [  9.],\n",
       "        [  3.],\n",
       "        [-17.],\n",
       "        [-17.]], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype, X.dtype, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593fa6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.,   1.],\n",
       "        [ -2.,  -1.],\n",
       "        [-10.,  -9.],\n",
       "        [  6.,   7.],\n",
       "        [  2.,   1.],\n",
       "        [  5.,   4.],\n",
       "        [  4.,   5.],\n",
       "        [ 10.,   3.],\n",
       "        [  8.,   9.],\n",
       "        [  4.,   5.],\n",
       "        [ -8.,  -7.],\n",
       "        [ -7., -10.],\n",
       "        [  7.,  -5.],\n",
       "        [  2.,   3.],\n",
       "        [ -9.,  -8.],\n",
       "        [ -4.,  -3.]], dtype=float32),\n",
       " array([[  1.],\n",
       "        [ -3.],\n",
       "        [-19.],\n",
       "        [ 13.],\n",
       "        [  3.],\n",
       "        [  9.],\n",
       "        [  9.],\n",
       "        [ 13.],\n",
       "        [ 17.],\n",
       "        [  9.],\n",
       "        [-15.],\n",
       "        [-17.],\n",
       "        [  2.],\n",
       "        [  5.],\n",
       "        [-17.],\n",
       "        [ -7.]], dtype=float32),\n",
       " array([[-4., -3.],\n",
       "        [ 5., -1.],\n",
       "        [-6., -5.],\n",
       "        [ 9.,  7.],\n",
       "        [-5., -8.]], dtype=float32),\n",
       " array([[ -7.],\n",
       "        [  4.],\n",
       "        [-11.],\n",
       "        [ 16.],\n",
       "        [-13.]], dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, random_state=1234)\n",
    "X_train, y_train,  X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d2ca9",
   "metadata": {},
   "source": [
    "## 4. Convert to Tensors for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "297f0b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  0.,   1.],\n",
       "         [ -2.,  -1.],\n",
       "         [-10.,  -9.],\n",
       "         [  6.,   7.],\n",
       "         [  2.,   1.],\n",
       "         [  5.,   4.],\n",
       "         [  4.,   5.],\n",
       "         [ 10.,   3.],\n",
       "         [  8.,   9.],\n",
       "         [  4.,   5.],\n",
       "         [ -8.,  -7.],\n",
       "         [ -7., -10.],\n",
       "         [  7.,  -5.],\n",
       "         [  2.,   3.],\n",
       "         [ -9.,  -8.],\n",
       "         [ -4.,  -3.]]),\n",
       " tensor([[-4., -3.],\n",
       "         [ 5., -1.],\n",
       "         [-6., -5.],\n",
       "         [ 9.,  7.],\n",
       "         [-5., -8.]]),\n",
       " tensor([[  1.],\n",
       "         [ -3.],\n",
       "         [-19.],\n",
       "         [ 13.],\n",
       "         [  3.],\n",
       "         [  9.],\n",
       "         [  9.],\n",
       "         [ 13.],\n",
       "         [ 17.],\n",
       "         [  9.],\n",
       "         [-15.],\n",
       "         [-17.],\n",
       "         [  2.],\n",
       "         [  5.],\n",
       "         [-17.],\n",
       "         [ -7.]]),\n",
       " tensor([[ -7.],\n",
       "         [  4.],\n",
       "         [-11.],\n",
       "         [ 16.],\n",
       "         [-13.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale the data\n",
    "#sc = StandardScaler()\n",
    "#X_train = sc.fit_transform(X_train)\n",
    "#X_test = sc.transform(X_test)\n",
    "# convert back to tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a24f6a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create tensorDatasets from the test and train data (both X and y)\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "# create tthe dataloaders from these datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "563b00cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNAddTwoIntegers(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FFNAddTwoIntegers, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(2,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8,1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe020e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/300, Loss: 19.2859\n",
      "Epoch 20/300, Loss: 0.2664\n",
      "Epoch 30/300, Loss: 0.1028\n",
      "Epoch 40/300, Loss: 0.0661\n",
      "Epoch 50/300, Loss: 0.0459\n",
      "Epoch 60/300, Loss: 0.0309\n",
      "Epoch 70/300, Loss: 0.0240\n",
      "Epoch 80/300, Loss: 0.0179\n",
      "Epoch 90/300, Loss: 0.0143\n",
      "Epoch 100/300, Loss: 0.0111\n",
      "Epoch 110/300, Loss: 0.0092\n",
      "Epoch 120/300, Loss: 0.0079\n",
      "Epoch 130/300, Loss: 0.0069\n",
      "Epoch 140/300, Loss: 0.0071\n",
      "Epoch 150/300, Loss: 0.0345\n",
      "Epoch 160/300, Loss: 0.0293\n",
      "Epoch 170/300, Loss: 0.0065\n",
      "Epoch 180/300, Loss: 0.0066\n",
      "Epoch 190/300, Loss: 0.0036\n",
      "Epoch 200/300, Loss: 0.0038\n",
      "Epoch 210/300, Loss: 0.0043\n",
      "Epoch 220/300, Loss: 0.0026\n",
      "Epoch 230/300, Loss: 0.0062\n",
      "Epoch 240/300, Loss: 0.0242\n",
      "Epoch 250/300, Loss: 0.0258\n",
      "Epoch 260/300, Loss: 0.0036\n",
      "Epoch 270/300, Loss: 0.0056\n",
      "Epoch 280/300, Loss: 0.0018\n",
      "Epoch 290/300, Loss: 0.0026\n",
      "Epoch 300/300, Loss: 0.0017\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "model = FFNAddTwoIntegers()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)\n",
    "\n",
    "num_epochs = 300\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch_X, batch_y in train_loader:\n",
    "       \n",
    "        y_pred = model(batch_X)\n",
    "        loss = criterion(y_pred, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95d3c52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: -7.5307745933532715\n"
     ]
    }
   ],
   "source": [
    "example_1 = torch.tensor([[-10.,4.]])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculation for inference\n",
    "with torch.no_grad():\n",
    "    prediction = model(example_1)\n",
    "\n",
    "print(\"Predicted value:\", prediction.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d302421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: -3.4432244300842285\n"
     ]
    }
   ],
   "source": [
    "example_1 = torch.tensor([[-10.,10.]])\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient calculation for inference\n",
    "with torch.no_grad():\n",
    "    prediction = model(example_1)\n",
    "\n",
    "print(\"Predicted value:\", prediction.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b62982e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4., -3.],\n",
       "        [ 5., -1.],\n",
       "        [-6., -5.],\n",
       "        [ 9.,  7.],\n",
       "        [-5., -8.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568d4ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted value: -6.999775409698486\n",
      "Predicted value: 4.106655120849609\n",
      "Predicted value: -10.999343872070312\n",
      "Predicted value: 16.026309967041016\n",
      "Predicted value: -13.055866241455078\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for test_samples in X_test:\n",
    "        prediction = model(test_samples)\n",
    "        print(\"Predicted value:\", prediction.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6510f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
